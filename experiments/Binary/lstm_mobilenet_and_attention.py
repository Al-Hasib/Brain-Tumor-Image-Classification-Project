# -*- coding: utf-8 -*-
"""Copy of lstm mobilenet and attention.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MHXX7_JOXFyFrex_Vscyk8wSeCZf8y6X
"""

import warnings
warnings.filterwarnings('ignore')

!unzip /content/drive/MyDrive/brain_mri_dataset.zip

import numpy as np
import matplotlib.pyplot as plt
import os
import math
import shutil
import glob
import numpy as np
import os
import math
import shutil
from keras.preprocessing.image import ImageDataGenerator
from keras.applications import VGG16
from keras.models import Model, Sequential
from keras.layers import GlobalAveragePooling2D, LSTM, Dense, Dropout, Layer, Input, TimeDistributed
from keras import backend as K, optimizers, initializers, regularizers, constraints
from keras.callbacks import ModelCheckpoint, EarlyStopping
import tensorflow as tf

# Counting the number of class from the dataset
Root_data = "/content/brain_mri_dataset"
number_of_image = {}
for dir in os.listdir(Root_data):
    number_of_image[dir] = len(os.listdir(os.path.join(Root_data, dir)))

number_of_image.items()

# Splitting the dataset into train, test, and validation

# creating a function for training, testing and validating
def datafolder(p, split):
    if not os.path.exists("./" + p):
        os.mkdir("./" + p)
        for dir in os.listdir(Root_data):
            os.makedirs("./" + p + "/" + dir)
            for img in np.random.choice(a=os.listdir(os.path.join(Root_data, dir)),
                                        size=(math.floor(split * number_of_image[dir]) - 2), replace=False):
                O = os.path.join(Root_data, dir, img)
                D = os.path.join("./" + p, dir)
                shutil.copy(O, D)
                os.remove(O)
    else:
        print(f"{p} folder exists")

datafolder("train", 0.7)

datafolder("test", 0.15)

datafolder("valid", 0.15)

Root_data = "/content/valid"
number_of_image = {}
for dir in os.listdir(Root_data):
    number_of_image[dir] = len(os.listdir(os.path.join(Root_data, dir)))
number_of_image.items()

from keras.layers import Layer
from keras import initializers, regularizers, constraints
from keras import backend as K

class Attention(Layer):
    def __init__(self, step_dim, W_regularizer=None, b_regularizer=None,
                 W_constraint=None, b_constraint=None, bias=True, **kwargs):
        self.supports_masking = True
        self.init = initializers.get('glorot_uniform')

        self.W_regularizer = regularizers.get(W_regularizer)
        self.b_regularizer = regularizers.get(b_regularizer)

        self.W_constraint = constraints.get(W_constraint)
        self.b_constraint = constraints.get(b_constraint)

        self.bias = bias
        self.step_dim = step_dim
        self.features_dim = 0
        super(Attention, self).__init__(**kwargs)

    def build(self, input_shape):
        assert len(input_shape) == 3

        self.W = self.add_weight(shape=(input_shape[-1],),
                                 initializer=self.init,
                                 regularizer=self.W_regularizer,
                                 constraint=self.W_constraint,
                                 name='{}_W'.format(self.name))
        self.features_dim = input_shape[-1]

        if self.bias:
            self.b = self.add_weight(shape=(input_shape[1],),
                                     initializer='zero',
                                     regularizer=self.b_regularizer,
                                     constraint=self.b_constraint,
                                     name='{}_b'.format(self.name))
        else:
            self.b = None

        self.built = True

    def compute_mask(self, input, input_mask=None):
        return None

    def call(self, x, mask=None):
        features_dim = self.features_dim
        step_dim = self.step_dim

        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),
                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))

        if self.bias:
            eij += self.b

        eij = K.tanh(eij)

        a = K.exp(eij)

        if mask is not None:
            a *= K.cast(mask, K.floatx())

        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())

        a = K.expand_dims(a)
        weighted_input = x * a
        return K.sum(weighted_input, axis=1)

    def compute_output_shape(self, input_shape):
        return input_shape[0], self.features_dim

    def get_config(self):
        config = super(Attention, self).get_config()
        config.update({
            'step_dim': self.step_dim,
            'W_regularizer': regularizers.serialize(self.W_regularizer),
            'b_regularizer': regularizers.serialize(self.b_regularizer),
            'W_constraint': constraints.serialize(self.W_constraint),
            'b_constraint': constraints.serialize(self.b_constraint),
            'bias': self.bias
        })
        return config

# Data preprocessing
def preprocessingimg1(path):
    image_data = ImageDataGenerator(zoom_range=0.2, shear_range=0.2, rescale=1/255, horizontal_flip=True)
    image = image_data.flow_from_directory(directory=path, target_size=(224, 224), batch_size=16, class_mode='binary')
    return image

def preprocessingimg2(path):
    image_data = ImageDataGenerator(rescale=1/255)
    image = image_data.flow_from_directory(directory=path, target_size=(224, 224), batch_size=16, class_mode='binary')
    return image

path = "/content/train"
train_data = preprocessingimg1(path)

path = "/content/test"
test_data = preprocessingimg2(path)

path = "/content/valid"
valid_data = preprocessingimg2(path)

# Feature extraction using MobileNet
from keras.applications import MobileNet
from keras.models import Model
from keras.layers import GlobalAveragePooling2D

# Load MobileNet model
base_model_mobilenet = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze base model layers
for layer in base_model_mobilenet.layers:
    layer.trainable = False

# Add custom layers for feature extraction
x = base_model_mobilenet.output
x = GlobalAveragePooling2D()(x)
feature_extractor_model = Model(inputs=base_model_mobilenet.input, outputs=x)

# Extract features from the images
def extract_features(data_generator, model):
    features = []
    labels = []
    for i in range(len(data_generator)):
        x, y = data_generator[i]
        feature = model.predict(x)
        features.append(feature)
        labels.append(y)
    return np.vstack(features), np.hstack(labels)

train_features, train_labels = extract_features(train_data, feature_extractor_model)
valid_features, valid_labels = extract_features(valid_data, feature_extractor_model)
test_features, test_labels = extract_features(test_data, feature_extractor_model)

# Reshape the features to be suitable for LSTM input
train_features = train_features.reshape(train_features.shape[0], 1, train_features.shape[1])
valid_features = valid_features.reshape(valid_features.shape[0], 1, valid_features.shape[1])
test_features = test_features.reshape(test_features.shape[0], 1, test_features.shape[1])

# LSTM model building with Attention
model_lstm = Sequential()
model_lstm.add(LSTM(128, input_shape=(1, train_features.shape[2]), return_sequences=True))
model_lstm.add(Dropout(0.5))
model_lstm.add(LSTM(64, return_sequences=True))
model_lstm.add(Dropout(0.5))
model_lstm.add(Attention(step_dim=1))
model_lstm.add(Dense(1, activation='sigmoid'))

model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

model_lstm.summary()

# Early stopping and model checkpoint
es = EarlyStopping(monitor="val_accuracy", min_delta=0.01, patience=15, verbose=1, mode='auto')
mc = ModelCheckpoint(monitor="val_accuracy", filepath="./cancer_detection_lstm_model.h5", verbose=1, save_best_only=True, mode='auto')
cd = [es, mc]

# Train the LSTM model
hs = model_lstm.fit(
    train_features, train_labels,
    epochs=50,
    batch_size=32,
    validation_data=(valid_features, valid_labels),
    callbacks=cd
)

from keras.models import load_model
from keras.utils import CustomObjectScope

# Load the best model with custom object scope
with CustomObjectScope({'Attention': Attention}):
    model = load_model("/content/cancer_detection_lstm_model.h5")

# Evaluate the model
accuracy = model.evaluate(test_features, test_labels)[1]
print(f"The accuracy of the LSTM model is {accuracy * 100}%")